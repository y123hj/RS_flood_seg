{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2478,"status":"ok","timestamp":1704270686723,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"},"user_tz":-480},"id":"CVMAKxxjXxXl","outputId":"bbd9e9b3-38ac-4855-bc43-d40fae32e9c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"yblKeu39Xznw","executionInfo":{"status":"ok","timestamp":1704270686724,"user_tz":-480,"elapsed":3,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","from torchvision.models.segmentation.fcn import fcn_resnet50\n","from osgeo import gdal, ogr\n","from torch.utils.data import DataLoader, Dataset, random_split\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"BDZzrtCbX93L","executionInfo":{"status":"ok","timestamp":1704270686724,"user_tz":-480,"elapsed":3,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","  '''\n","  自定义数据集类\n","  '''\n","  def __init__(self,images_dir, mask_dir, txt_path, transform=None):\n","    self.images_dir = images_dir\n","    self.mask_dir = mask_dir\n","    self.imagelist = self.get_imagelist(txt_path)\n","    self.transform = transform\n","\n","  def get_imagelist(self,txt_path):\n","    with open(txt_path,'r') as f:\n","      imagelist = f.readlines()\n","    return imagelist\n","\n","  def __len__(self):\n","    # 返回数据集的大小\n","    return len(self.imagelist)\n","\n","  def __getitem__(self,index):\n","    # 获取单个图片\n","    img_path = os.path.join(self.images_dir,self.imagelist[index][:-1])\n","    mask_path = os.path.join(self.mask_dir,self.imagelist[index][:-1])\n","    raster_file1 = gdal.Open(img_path)\n","    raster_array1 = raster_file1.ReadAsArray()\n","    raster_file2 = gdal.Open(mask_path)\n","    raster_array2 = raster_file2.ReadAsArray()\n","    # x数据的处理\n","    img_data = np.zeros((4,raster_array1.shape[1],raster_array1.shape[2]))\n","    img_data[0] = raster_array1[2,:,:]\n","    img_data[1] = raster_array1[7,:,:]\n","    img_data[2] = raster_array1[10,:,:]\n","    img_data[3] = raster_array2[2]\n","    img_data = np.nan_to_num(img_data)  # 用0填充img中的nan\n","    img_data[0:3] = img_data[0:3] / 5000 # 归一化\n","    img_data[3] = ( img_data[3] - np.min(img_data[3]) ) / ( np.max(img_data[3]) - np.min(img_data[3]) ) # 归一化\n","    img_data[3][np.isnan(img_data[3])] = 0\n","    img_data[3][np.isinf(img_data[3])] = 0\n","    img = img_data.transpose(1,2,0) # channel first\n","\n","    # y数据的处理\n","\n","    mask_data = raster_array2[3] # 第四个波段label\n","    mask_data = np.nan_to_num(mask_data) # 用0填充mask中的nan\n","    mask = np.zeros([512,512])\n","    mask[mask_data == 0] = 0\n","    mask[mask_data == 1] = 0\n","    mask[mask_data == 2] = 1\n","    mask[mask_data == 3] = 1\n","    # 数据增强\n","    if self.transform:\n","      image = self.transform(img)\n","      mask = self.transform(mask)\n","    return image,mask\n","\n","  def get_image_names(self, idx):\n","    return self.imagelist[idx]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"a7GmBvDDYDIK","executionInfo":{"status":"ok","timestamp":1704270686724,"user_tz":-480,"elapsed":3,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"outputs":[],"source":["# 数据强化\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","# 创建数据集\n","img_path = '/content/drive/MyDrive/RS/HAND/S2_split/'\n","mask_path = '/content/drive/MyDrive/RS/HAND/S1_split/'\n","train_path = '/content/drive/MyDrive/RS/HAND/train.txt'\n","test_path = '/content/drive/MyDrive/RS/HAND/test.txt'\n","\n","train_dataset = CustomDataset(img_path,mask_path,train_path,transform)\n","test_dataset = CustomDataset(img_path,mask_path,test_path,transform)\n","\n","# 创建数据集加载器\n","train_loader = DataLoader(train_dataset,batch_size=4,shuffle=True)\n","test_loader = DataLoader(test_dataset,batch_size=4,shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1704270686724,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"},"user_tz":-480},"id":"s_z-j7VhYIfJ"},"outputs":[],"source":["# 定义块\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,\n","                      stride=1, padding_mode='reflect', bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            # nn.InstanceNorm2d(out_channels),  # nnUNet\n","\n","            nn.ReLU(inplace=True),\n","            # nn.LeakyReLU(),  # nnUNet\n","\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1,\n","                      stride=1, padding_mode='reflect', bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            # nn.InstanceNorm2d(out_channels),  # nnUNet\n","\n","            nn.ReLU(inplace=True)\n","            # nn.LeakyReLU()  # nnUNet\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","\n","class UpSample(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UpSample, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"zU4KF2bAYLf3","executionInfo":{"status":"ok","timestamp":1704270686724,"user_tz":-480,"elapsed":2,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"outputs":[],"source":["# 定义UNet模型\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=4, out_channels=2):\n","        super().__init__()\n","        self.conv1 = DoubleConv(in_channels, 64)\n","        self.down1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = DoubleConv(64, 128)\n","        self.down2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv3 = DoubleConv(128, 256)\n","        self.down3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv4 = DoubleConv(256, 512)\n","        self.down4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.conv_mid = DoubleConv(512, 1024)\n","\n","        self.up1 = UpSample(1024, 512)\n","        self.conv5 = DoubleConv(1024,512)\n","        self.up2 = UpSample(512, 256)\n","        self.conv6 = DoubleConv(512,256)\n","        self.up3 = UpSample(256, 128)\n","        self.conv7 = DoubleConv(256,128)\n","        self.up4 = UpSample(128, 64)\n","        self.conv8 = DoubleConv(128,64)\n","\n","        self.out_channel = nn.Conv2d(64, out_channels, kernel_size=1, stride=1)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        conv1 = self.conv1(x)\n","        down1 = self.down1(conv1)\n","        conv2 = self.conv2(down1)\n","        down2 = self.down2(conv2)\n","        conv3 = self.conv3(down2)\n","        down3 = self.down3(conv3)\n","        conv4 = self.conv4(down3)\n","        down4 = self.down4(conv4)\n","\n","        conv_mid = self.conv_mid(down4)\n","\n","        up1 = self.up1(conv_mid)\n","        cat1 = torch.cat([up1, conv4], dim=1)\n","        down5  = self.conv5(cat1)\n","\n","        up2 = self.up2(down5)\n","        cat2 = torch.cat([up2, conv3], dim=1)\n","        down6  = self.conv6(cat2)\n","\n","        up3 = self.up3(down6)\n","        cat3 = torch.cat([up3, conv2], dim=1)\n","        down7  = self.conv7(cat3)\n","\n","        up4 = self.up4(down7)\n","        cat4 = torch.cat([up4, conv1], dim=1)\n","        down8  = self.conv8(cat4)\n","\n","        out_channel = self.out_channel(down8)\n","\n","        return out_channel"]},{"cell_type":"code","source":["model = UNet()\n","# 定义损失函数、优化器\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"],"metadata":{"id":"gnfoM3FXh37i","executionInfo":{"status":"ok","timestamp":1704270687188,"user_tz":-480,"elapsed":466,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def computeIOU(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  intersection = torch.sum(output * target)\n","  union = torch.sum(target) + torch.sum(output) - intersection\n","  iou = (intersection + .0000001) / (union + .0000001)\n","\n","  if iou != iou:\n","    print(\"failed, replacing with 0\")\n","    iou = torch.tensor(0).float()\n","\n","  return iou\n","\n","def computeAccuracy(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  correct = torch.sum(output.eq(target))\n","\n","  return correct.float() / len(target)\n","\n","def truePositives(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  correct = torch.sum(output * target)\n","\n","  return correct\n","\n","def trueNegatives(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  output = (output == 0)\n","  target = (target == 0)\n","  correct = torch.sum(output * target)\n","\n","  return correct\n","\n","def falsePositives(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  output = (output == 1)\n","  target = (target == 0)\n","  correct = torch.sum(output * target)\n","\n","  return correct\n","\n","def falseNegatives(output, target):\n","  output = torch.argmax(output, dim=1).flatten()\n","  target = target.flatten()\n","  no_ignore = target.ne(255).cuda()\n","  output = output.masked_select(no_ignore)\n","  target = target.masked_select(no_ignore)\n","  output = (output == 0)\n","  target = (target == 1)\n","  correct = torch.sum(output * target)\n","\n","  return correct"],"metadata":{"id":"CDgWDCpo5K9v","executionInfo":{"status":"ok","timestamp":1704270687188,"user_tz":-480,"elapsed":3,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704270687188,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"},"user_tz":-480},"id":"F_oaqz-8YOvp","outputId":"f53ab47d-a7ff-406c-ef6c-e8b0c467f0cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["UNet(\n","  (conv1): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (down1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (down2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv3): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (down3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv4): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (down4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv_mid): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (up1): UpSample(\n","    (block): Sequential(\n","      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (conv5): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (up2): UpSample(\n","    (block): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (conv6): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (up3): UpSample(\n","    (block): Sequential(\n","      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (conv7): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (up4): UpSample(\n","    (block): Sequential(\n","      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (conv8): DoubleConv(\n","    (block): Sequential(\n","      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (out_channel): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":19}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# 把网络设置在训练模式\n","model.train()\n","model.to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"VKy15D6Y1dIZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704271656748,"user_tz":-480,"elapsed":969562,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}},"outputId":"645b1fd4-975b-49b9-c581-ee2d306e006a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-df445a768032>:36: RuntimeWarning: invalid value encountered in divide\n","  img_data[3] = ( img_data[3] - np.min(img_data[3]) ) / ( np.max(img_data[3]) - np.min(img_data[3]) ) # 归一化\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Loss: 0.7432005405426025\n","Epoch 2/20, Loss: 0.10914553701877594\n","Epoch 3/20, Loss: 0.10121631622314453\n","Epoch 4/20, Loss: 0.08791816979646683\n","Epoch 5/20, Loss: 0.09102699160575867\n","Epoch 6/20, Loss: 0.08229129016399384\n","Epoch 7/20, Loss: 0.12367458641529083\n","Epoch 8/20, Loss: 0.34854093194007874\n","Epoch 9/20, Loss: 0.06545379012823105\n","Epoch 10/20, Loss: 0.04299104958772659\n","Epoch 11/20, Loss: 1.4134955406188965\n","Epoch 12/20, Loss: 0.24437405169010162\n","Epoch 13/20, Loss: 0.5596656799316406\n","Epoch 14/20, Loss: 0.3768824338912964\n","Epoch 15/20, Loss: 0.08598354458808899\n","Epoch 16/20, Loss: 0.1970195323228836\n","Epoch 17/20, Loss: 0.0819663554430008\n","Epoch 18/20, Loss: 0.17551735043525696\n","Epoch 19/20, Loss: 0.025392521172761917\n","Epoch 20/20, Loss: 0.09587084501981735\n"]}],"source":["loss_history = [] #训练过程中的loss数据\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    for i,data in enumerate(train_loader,0):\n","        inputs, targets = data[0].to(device), data[1].to(device)\n","        inputs = inputs.float()\n","        targets = targets.long()\n","        #(0) 复位优化器的梯度\n","        optimizer.zero_grad()\n","        #(1) 前向计算\n","        y_pred = model(inputs)\n","        #(2) 计算loss\n","        targets = targets.squeeze(1)\n","        loss = loss_fn(y_pred, targets)\n","        #(3) 反向求导\n","        loss.backward()\n","        #(4) 反向迭代\n","        optimizer.step()\n","\n","    # 记录训练过程中的准确率\n","    loss_history.append(loss.item())\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"]},{"cell_type":"code","source":["model.eval()\n","iou = []\n","acc = []\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","for idx in range(len(test_dataset)):\n","  inputs, labels = test_dataset[idx]\n","  inputs = inputs.unsqueeze(0).float()\n","  inputs = inputs.to(device)\n","  labels = labels.to(device)\n","  with torch.no_grad():\n","    outputs = model(inputs)\n","  test_acc = computeAccuracy(outputs,labels).cpu().numpy()\n","  acc.append(test_acc)\n","  test_iou = computeIOU(outputs,labels).cpu().numpy()\n","  iou.append(test_iou)\n","\n","  TP += truePositives(outputs,labels).cpu().numpy()\n","  TN += trueNegatives(outputs,labels).cpu().numpy()\n","  FP += falsePositives(outputs,labels).cpu().numpy()\n","  FN += falseNegatives(outputs,labels).cpu().numpy()\n","\n","mean_iou = sum(iou) / len(iou)\n","mean_acc = sum(acc) / len(acc)"],"metadata":{"id":"m-7OHm7a5bMf","executionInfo":{"status":"ok","timestamp":1704271770757,"user_tz":-480,"elapsed":114019,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["print(mean_acc)\n","print(mean_iou)\n","\n","print(TP)\n","print(TN)\n","print(FP)\n","print(FN)\n","\n","confusion_matrix = [TP,TN,FP,FN]"],"metadata":{"id":"su8qu8Xm5gJj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704271864036,"user_tz":-480,"elapsed":379,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}},"outputId":"d84fdd0f-9b4b-4606-86e9-c18d149306c2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9679714340761484\n","0.45595493663589126\n","1238935.0\n","19822141\n","176039\n","520837\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"id":"fxM-dC0MYhZJ","executionInfo":{"status":"ok","timestamp":1704271880590,"user_tz":-480,"elapsed":1207,"user":{"displayName":"Hongjie Yu","userId":"07472965283071684648"}}},"outputs":[],"source":["# 保存模型参数为字典\n","torch.save(model.state_dict(), '/content/drive/MyDrive/RS/HAND/UNet_S2D_state_dict.pth')\n","np.savetxt('/content/drive/MyDrive/RS/HAND/S2D_evaluate/S2D_UNet_loss.txt', loss_history)\n","np.savetxt('/content/drive/MyDrive/RS/HAND/S2D_evaluate/S2D_UNet_acc.txt', acc)\n","np.savetxt('/content/drive/MyDrive/RS/HAND/S2D_evaluate/S2D_UNet_iou.txt', iou)\n","np.savetxt('/content/drive/MyDrive/RS/HAND/S2D_evaluate/S2D_UNet_confusion_matrix.txt', confusion_matrix)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyONI1EgptKXXwdlzAJqNue7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}